{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at11TensorMaker11make_tensorEv'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch._C._distributed_c10d'; 'torch._C' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/thezingaro/Developer/ABS-Simulations-Comparison/predictiveGlobalScaling/workload_predictor/data-analysis.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thezingaro/Developer/ABS-Simulations-Comparison/predictiveGlobalScaling/workload_predictor/data-analysis.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thezingaro/Developer/ABS-Simulations-Comparison/predictiveGlobalScaling/workload_predictor/data-analysis.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/thezingaro/Developer/ABS-Simulations-Comparison/predictiveGlobalScaling/workload_predictor/data-analysis.ipynb#ch0000000?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mimport\u001b[39;00m seed_everything\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thezingaro/Developer/ABS-Simulations-Comparison/predictiveGlobalScaling/workload_predictor/data-analysis.ipynb#ch0000000?line=5'>6</a>\u001b[0m seed_everything(\u001b[39m42\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/__init__.py:30\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/__init__.py?line=26'>27</a>\u001b[0m     _logger\u001b[39m.\u001b[39maddHandler(logging\u001b[39m.\u001b[39mStreamHandler())\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/__init__.py?line=27'>28</a>\u001b[0m     _logger\u001b[39m.\u001b[39mpropagate \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/__init__.py?line=29'>30</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m Callback  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/__init__.py?line=30'>31</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningDataModule, LightningModule  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/__init__.py?line=31'>32</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer  \u001b[39m# noqa: E402\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/callbacks/__init__.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/callbacks/__init__.py?line=23'>24</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprediction_writer\u001b[39;00m \u001b[39mimport\u001b[39;00m BasePredictionWriter\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/callbacks/__init__.py?line=24'>25</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprogress\u001b[39;00m \u001b[39mimport\u001b[39;00m ProgressBar, ProgressBarBase, RichProgressBar, TQDMProgressBar\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/callbacks/__init__.py?line=25'>26</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpruning\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelPruning\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/callbacks/__init__.py?line=26'>27</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantization\u001b[39;00m \u001b[39mimport\u001b[39;00m QuantizationAwareTraining\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/callbacks/__init__.py?line=27'>28</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrich_model_summary\u001b[39;00m \u001b[39mimport\u001b[39;00m RichModelSummary\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/callbacks/pruning.py:31\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/callbacks/pruning.py?line=28'>29</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/callbacks/pruning.py?line=29'>30</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m Callback\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/callbacks/pruning.py?line=30'>31</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlightning\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningModule\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/callbacks/pruning.py?line=31'>32</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply_func\u001b[39;00m \u001b[39mimport\u001b[39;00m apply_to_collection\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/callbacks/pruning.py?line=32'>33</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m MisconfigurationException\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/__init__.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/__init__.py?line=0'>1</a>\u001b[0m \u001b[39m# Copyright The PyTorch Lightning team.\u001b[39;00m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/__init__.py?line=1'>2</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/__init__.py?line=2'>3</a>\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/__init__.py?line=11'>12</a>\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/__init__.py?line=12'>13</a>\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/__init__.py?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatamodule\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningDataModule\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/__init__.py?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlightning\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningModule\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/__init__.py?line=17'>18</a>\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mLightningDataModule\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLightningModule\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py:41\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py?line=38'>39</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelIO\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py?line=39'>40</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloggers\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningLoggerBase\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py?line=40'>41</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconnectors\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_connector\u001b[39;00m \u001b[39mimport\u001b[39;00m _DataHookSelector\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py?line=41'>42</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconnectors\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlogger_connector\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfx_validator\u001b[39;00m \u001b[39mimport\u001b[39;00m _FxValidator\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py?line=42'>43</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_WINDOWS, _TORCH_GREATER_EQUAL_1_10, GradClipAlgorithmType\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/__init__.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/__init__.py?line=0'>1</a>\u001b[0m \u001b[39m# Copyright The PyTorch Lightning team.\u001b[39;00m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/__init__.py?line=1'>2</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/__init__.py?line=2'>3</a>\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/__init__.py?line=11'>12</a>\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/__init__.py?line=12'>13</a>\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/__init__.py?line=13'>14</a>\u001b[0m \u001b[39m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/__init__.py?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/__init__.py?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mseed\u001b[39;00m \u001b[39mimport\u001b[39;00m seed_everything\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/__init__.py?line=18'>19</a>\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mTrainer\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mseed_everything\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=30'>31</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=32'>33</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=33'>34</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maccelerators\u001b[39;00m \u001b[39mimport\u001b[39;00m Accelerator, GPUAccelerator, HPUAccelerator, IPUAccelerator, TPUAccelerator\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=34'>35</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m Callback, EarlyStopping, ModelCheckpoint, ProgressBarBase\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=35'>36</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprediction_writer\u001b[39;00m \u001b[39mimport\u001b[39;00m BasePredictionWriter\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/__init__.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/__init__.py?line=0'>1</a>\u001b[0m \u001b[39m# Copyright The PyTorch Lightning team.\u001b[39;00m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/__init__.py?line=1'>2</a>\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/__init__.py?line=2'>3</a>\u001b[0m \u001b[39m# you may not use this file except in compliance with the License.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/__init__.py?line=10'>11</a>\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/__init__.py?line=11'>12</a>\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/__init__.py?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maccelerators\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maccelerator\u001b[39;00m \u001b[39mimport\u001b[39;00m Accelerator  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/__init__.py?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maccelerators\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcpu\u001b[39;00m \u001b[39mimport\u001b[39;00m CPUAccelerator  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/__init__.py?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maccelerators\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgpu\u001b[39;00m \u001b[39mimport\u001b[39;00m GPUAccelerator  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/__init__.py?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maccelerators\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhpu\u001b[39;00m \u001b[39mimport\u001b[39;00m HPUAccelerator  \u001b[39m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/cpu.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/cpu.py?line=15'>16</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/cpu.py?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maccelerators\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maccelerator\u001b[39;00m \u001b[39mimport\u001b[39;00m Accelerator\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/cpu.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m \u001b[39mimport\u001b[39;00m device_parser\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/cpu.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m MisconfigurationException\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/accelerators/cpu.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m _DEVICE\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, List, MutableSequence, Optional, Tuple, Union\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py?line=15'>16</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplugins\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvironments\u001b[39;00m \u001b[39mimport\u001b[39;00m TorchElasticEnvironment\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtuner\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto_gpu_select\u001b[39;00m \u001b[39mimport\u001b[39;00m pick_multiple_gpus\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m MisconfigurationException\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/__init__.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/__init__.py?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplugins\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprecision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu\u001b[39;00m \u001b[39mimport\u001b[39;00m TPUPrecisionPlugin\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/__init__.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplugins\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprecision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu_bf16\u001b[39;00m \u001b[39mimport\u001b[39;00m TPUBf16PrecisionPlugin\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/__init__.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplugins\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining_type\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mddp\u001b[39;00m \u001b[39mimport\u001b[39;00m DDPPlugin\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/__init__.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplugins\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining_type\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mddp2\u001b[39;00m \u001b[39mimport\u001b[39;00m DDP2Plugin\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/__init__.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplugins\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining_type\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mddp_spawn\u001b[39;00m \u001b[39mimport\u001b[39;00m DDPSpawnPlugin\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplugins\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining_type\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mddp\u001b[39;00m \u001b[39mimport\u001b[39;00m DDPPlugin  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplugins\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining_type\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mddp2\u001b[39;00m \u001b[39mimport\u001b[39;00m DDP2Plugin  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/__init__.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplugins\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining_type\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mddp_spawn\u001b[39;00m \u001b[39mimport\u001b[39;00m DDPSpawnPlugin  \u001b[39m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py?line=0'>1</a>\u001b[0m \u001b[39m# Copyright The PyTorch Lightning team.\u001b[39;00m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py?line=1'>2</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py?line=2'>3</a>\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py?line=11'>12</a>\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py?line=12'>13</a>\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstrategies\u001b[39;00m \u001b[39mimport\u001b[39;00m DDPStrategy\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m \u001b[39mimport\u001b[39;00m rank_zero_deprecation\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py?line=17'>18</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDDPPlugin\u001b[39;00m(DDPStrategy):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/strategies/__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/strategies/__init__.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstrategies\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfully_sharded\u001b[39;00m \u001b[39mimport\u001b[39;00m DDPFullyShardedStrategy  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/strategies/__init__.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstrategies\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhorovod\u001b[39;00m \u001b[39mimport\u001b[39;00m HorovodStrategy  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/strategies/__init__.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstrategies\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhpu_parallel\u001b[39;00m \u001b[39mimport\u001b[39;00m HPUParallelStrategy  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/strategies/__init__.py?line=22'>23</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstrategies\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mipu\u001b[39;00m \u001b[39mimport\u001b[39;00m IPUStrategy  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/strategies/__init__.py?line=23'>24</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstrategies\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparallel\u001b[39;00m \u001b[39mimport\u001b[39;00m ParallelStrategy  \u001b[39m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/strategies/hpu_parallel.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/strategies/hpu_parallel.py?line=20'>21</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/strategies/hpu_parallel.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moverrides\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningDistributedModule\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/strategies/hpu_parallel.py?line=22'>23</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moverrides\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtorch_distributed\u001b[39;00m \u001b[39mimport\u001b[39;00m broadcast_object_list\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/strategies/hpu_parallel.py?line=23'>24</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplugins\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcheckpoint_plugin\u001b[39;00m \u001b[39mimport\u001b[39;00m CheckpointIO\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/strategies/hpu_parallel.py?line=24'>25</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplugins\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhpu_plugin\u001b[39;00m \u001b[39mimport\u001b[39;00m HPUCheckpointIO\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/overrides/torch_distributed.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/overrides/torch_distributed.py?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/overrides/torch_distributed.py?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/overrides/torch_distributed.py?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_distributed_c10d\u001b[39;00m \u001b[39mimport\u001b[39;00m ProcessGroup\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/overrides/torch_distributed.py?line=10'>11</a>\u001b[0m _pickler \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mPickler\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/pytorch_lightning/overrides/torch_distributed.py?line=11'>12</a>\u001b[0m _unpickler \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mUnpickler\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch._C._distributed_c10d'; 'torch._C' is not a package"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(42)\n",
    "# sets seeds for numpy, torch and python.random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train, val and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EnronDataset(Dataset):\n",
    "    def __init__(self, df, target_col, preprocess=True):\n",
    "        df = self.preprocess(df) if preprocess else df\n",
    "        attr_cols = list(df.columns)\n",
    "        del(attr_cols[attr_cols.index(target_col)])\n",
    "        self.x = torch.from_numpy(df[attr_cols].to_numpy()).float()\n",
    "        self.y = torch.from_numpy(df[target_col].to_numpy()).float()\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        hour = pd.get_dummies(df['hour'], prefix_sep='_', prefix='hour', drop_first=True)\n",
    "        day = pd.get_dummies(df['day'], prefix_sep='_', prefix='day', drop_first=True)\n",
    "        month = pd.get_dummies(df['month'], prefix_sep='_', prefix='month', drop_first=True)\n",
    "        weekday = pd.get_dummies(df['weekday'], prefix_sep='_', prefix='weekday', drop_first=True)\n",
    "\n",
    "        # Merge the original df with the categorical computed feature (order id preserved)\n",
    "        df = pd.concat([df, hour, day, month, weekday], axis=1, )\n",
    "\n",
    "        # drop the numerical df attributes\n",
    "        df.drop(\n",
    "            columns=['hour', 'day', 'month', 'weekday'], \n",
    "            axis=1, \n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\n",
    "    'data/enron_train_hourly.csv',\n",
    ")\n",
    "df_val = pd.read_csv(\n",
    "    'data/enron_val_hourly.csv',\n",
    ")\n",
    "df_train_val = pd.read_csv(\n",
    "    'data/enron_train+val_hourly.csv',\n",
    ")\n",
    "df_test_weekday = pd.read_csv(\n",
    "    'data/enron_wednesday-15-february_hourly.csv',\n",
    ")\n",
    "df_test_holyday = pd.read_csv(\n",
    "    'data/enron_sunday_10_june_hourly.csv',\n",
    ")\n",
    "\n",
    "target_col = 'counter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    EnronDataset(df_train, target_col),\n",
    "    # num_workers=os.cpu_count(),\n",
    "    num_workers=0,\n",
    "    batch_size=len(df_train)\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    EnronDataset(df_val, target_col),\n",
    "    # num_workers=os.cpu_count(),\n",
    "    num_workers=0,\n",
    "    batch_size=len(df_val)\n",
    ")\n",
    "\n",
    "train_val_loader = DataLoader(\n",
    "    EnronDataset(df_train_val, target_col),\n",
    "    # num_workers=os.cpu_count(),\n",
    "    num_workers=0,\n",
    "    batch_size=len(df_train_val)\n",
    ")\n",
    "\n",
    "test_weekday_loader = DataLoader(\n",
    "    EnronDataset(df_val, target_col),\n",
    "    # num_workers=os.cpu_count(),\n",
    "    num_workers=0,\n",
    "    batch_size=len(df_test_weekday)\n",
    ")\n",
    "\n",
    "test_holyday_loader = DataLoader(\n",
    "    EnronDataset(df_val, target_col),\n",
    "    # num_workers=os.cpu_count(),\n",
    "    num_workers=0,\n",
    "    batch_size=len(df_test_holyday)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Regression Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "class LinearNetwork(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_size, hidden_size), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y = y.view(y.size(0), 1)\n",
    "        y_pred = self.mlp(x)\n",
    "        loss = F.mse_loss(y_pred, y)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y = y.view(y.size(0), 1)\n",
    "        y_pred = self.mlp(x)\n",
    "        loss = F.mse_loss(y_pred, y)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y = y.view(y.size(0), 1)\n",
    "        y_pred = self.mlp(x)\n",
    "        print(\"test_predictions\", y_pred)\n",
    "        loss = F.mse_loss(y_pred, y)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.1)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.9999)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "model = LinearNetwork(\n",
    "    input_size=len(df_train.columns)-1,\n",
    "    hidden_size=128,\n",
    "    output_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "trainer = Trainer(\n",
    "    deterministic=True, \n",
    "    max_epochs=4000,\n",
    "    # log_every_n_steps=1,\n",
    "    check_val_every_n_epoch=100,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")]\n",
    ")\n",
    "trainer.fit(\n",
    "    model=model, \n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model=model, \n",
    "    train_dataloaders=train_val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(\n",
    "    ckpt_path=\"best\", \n",
    "    dataloaders=test_weekday_loader,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(\n",
    "    ckpt_path=\"best\", \n",
    "    dataloaders=test_holyday_loader,\n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55379ab208a5a1c57376d9a6dc7c2922632f62645619bc8dfbc6910698e69e79"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
