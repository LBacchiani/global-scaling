{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(42, workers=True)\n",
    "# sets seeds for numpy, torch and python.random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train, val and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_all = pd.read_csv(\n",
    "    'data/all_emails_categorical_hour.csv',\n",
    ")\n",
    "df_train = pd.read_csv(\n",
    "    'data/train_emails_categorical_hour.csv',\n",
    ")\n",
    "df_val = pd.read_csv(\n",
    "    'data/val_emails_categorical_hour.csv',\n",
    ")\n",
    "df_test = pd.read_csv(\n",
    "    'data/tuesday_27_june_emails_categorical_hour.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter</th>\n",
       "      <th>hour_1</th>\n",
       "      <th>hour_2</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_4</th>\n",
       "      <th>hour_5</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_7</th>\n",
       "      <th>hour_8</th>\n",
       "      <th>hour_9</th>\n",
       "      <th>...</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   counter  hour_1  hour_2  hour_3  hour_4  hour_5  hour_6  hour_7  hour_8  \\\n",
       "0        1       0       0       0       0       0       0       0       0   \n",
       "1       75       0       0       0       0       0       0       0       0   \n",
       "2        6       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   hour_9  ...  month_9  month_10  month_11  month_12  weekday_1  weekday_2  \\\n",
       "0       0  ...        0         0         0         0          1          0   \n",
       "1       0  ...        0         0         0         0          0          0   \n",
       "2       0  ...        0         0         0         0          0          0   \n",
       "\n",
       "   weekday_3  weekday_4  weekday_5  weekday_6  \n",
       "0          0          0          0          0  \n",
       "1          1          0          0          0  \n",
       "2          0          1          0          0  \n",
       "\n",
       "[3 rows x 71 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EnronDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'counter'\n",
    "train_cols = list(df_all.columns)\n",
    "del(train_cols[train_cols.index('counter')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    EnronDataset(\n",
    "        torch.from_numpy(df_train[train_cols].to_numpy()).float(),\n",
    "        torch.from_numpy(df_train[target_col].to_numpy()).float(),\n",
    "    ),\n",
    "    num_workers=os.cpu_count(),\n",
    "    batch_size=len(df_train)\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    EnronDataset(\n",
    "        torch.from_numpy(df_val[train_cols].to_numpy()).float(),\n",
    "        torch.from_numpy(df_val[target_col].to_numpy()).float(),\n",
    "    ),\n",
    "    num_workers=os.cpu_count(),\n",
    "    batch_size=len(df_val)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    EnronDataset(\n",
    "        torch.from_numpy(df_test[train_cols].to_numpy()).float(),\n",
    "        torch.from_numpy(df_test[target_col].to_numpy()).float(),\n",
    "    ),\n",
    "    num_workers=os.cpu_count(),\n",
    "    batch_size=len(df_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Regression Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "class LinearNetwork(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(70, 64), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(64, 32), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y = y.view(y.size(0), 1)\n",
    "        y_pred = self.mlp(x)\n",
    "        loss = F.mse_loss(y_pred, y)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y = y.view(y.size(0), 1)\n",
    "        y_pred = self.mlp(x)\n",
    "        loss = F.mse_loss(y_pred, y)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y = y.view(y.size(0), 1)\n",
    "        y_pred = self.mlp(x)\n",
    "        print(\"test_predictions\", y_pred)\n",
    "        loss = F.mse_loss(y_pred, y)\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.1)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.9999)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "model = LinearNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | mlp  | Sequential | 6.7 K \n",
      "------------------------------------\n",
      "6.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.7 K     Total params\n",
      "0.027     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 699: 100%|██████████| 2/2 [03:38<00:00, 109.49s/it, loss=218, v_num=20]    \n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "trainer = Trainer(\n",
    "    deterministic=True, \n",
    "    max_epochs=4000,\n",
    "    log_every_n_steps=1,\n",
    "    check_val_every_n_epoch=100,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")]\n",
    ")\n",
    "trainer.fit(\n",
    "    model=model, \n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/thezingaro/Developer/ABS-Simulations-Comparison/predictiveGlobalScaling/workload_predictor/lightning_logs/version_20/checkpoints/epoch=699-step=700.ckpt\n",
      "Loaded model weights from checkpoint at /home/thezingaro/Developer/ABS-Simulations-Comparison/predictiveGlobalScaling/workload_predictor/lightning_logs/version_20/checkpoints/epoch=699-step=700.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]test_predictions tensor([[  14.8872],\n",
      "        [   8.1838],\n",
      "        [  10.0693],\n",
      "        [  11.8793],\n",
      "        [   9.1408],\n",
      "        [  11.1155],\n",
      "        [  16.5406],\n",
      "        [  14.8124],\n",
      "        [  26.9808],\n",
      "        [  17.7927],\n",
      "        [  11.7585],\n",
      "        [  19.3534],\n",
      "        [   7.3737],\n",
      "        [  20.7238],\n",
      "        [  10.7997],\n",
      "        [  32.6084],\n",
      "        [1129.9993],\n",
      "        [   7.6053],\n",
      "        [   6.0110],\n",
      "        [   8.0640],\n",
      "        [   6.4636],\n",
      "        [   3.1282],\n",
      "        [   5.5628],\n",
      "        [   9.0316]])\n",
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.86it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            54.17729187011719\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 54.17729187011719}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(\n",
    "    ckpt_path=\"best\", \n",
    "    dataloaders=test_loader,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.tensor([13,12,15,12,15,13,15,22,22,24,21,17,10,14,12,24,1121,7,6,8,7,5,4,5]).float()\n",
    "targets = torch.tensor([9,4,12,10,9,6,24,36,29,26,12,23,14,21,19,13,1128,1,5,8,6,5,2,1]).float()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55379ab208a5a1c57376d9a6dc7c2922632f62645619bc8dfbc6910698e69e79"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
